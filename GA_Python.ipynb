{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms in Python\n",
    "\n",
    "#### Dr. Mathew Smith, ADACS, Swinburne University of Technology\n",
    "\n",
    "The application of Genetic Algorithsm (GA's) has become increasingly popular in engineering, mathematics and science research for studies and applications involving optimization. In this notebook, we examine the implementation of a Differential Evolution (DE) algorithm - a type of Genetic Algorithm - which emulates biological evolution for solution of an optimization problem. \n",
    "\n",
    "## Motivation\n",
    "\n",
    "Consider the Goldstein-Price function f(X,Y), which has a global minima of f(X,Y) = 3 at X = 0 and Y = -1:\n",
    "\n",
    "\\begin{align}\n",
    "f(X,Y) = (1 + (X+Y+1)^2(19-14X+3X^2-14Y+6XY+3Y^2)) \\\\\n",
    "                (30 + (2X-3Y)^2(18-32X+12X^2+48Y-36XY+27Y^2))\n",
    "                \\end{align}\n",
    "\n",
    "Suppose we wish to calculate the values of X and Y which provide the minimum (or maximum) value of f(X,Y). One may use a gradient-based approach - such as a Newton-Raphson based method - which employs partial derivitives of f(X,Y) with respect to X and Y and uses them to iterate towards the best values of X and Y. This approach may be complicated by the presence of local minima, which tend to trap solutions of this kind. So, in this case, we plan on using a Genetic Algorithm, which is a heuristic approach.\n",
    "\n",
    "## Genetic Algorithm Preamble\n",
    "\n",
    "In the equation above we have two solution parameters (specifically X and Y) which we shall refer to as genomes, collectively representing a solutions's DNA. For any given DNA pair, we have a value of f(X,Y) which we shall refer to as the \"fitness\" - which tells us \"how good\" the DNA is. Let's start by writing some Python code which computes the fitness based on the DNA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def ComputeFitness(X):\n",
    "        # Compute the fitness based on genetic data X\n",
    "        # X is an array of dimension (NO_VAR)\n",
    "        # The goal of the GA is the find the value of X which results\n",
    "        # in a maximum or mimimum value of this fitness function.\n",
    "\n",
    "        # Compute the Goldstein-Price function (two variables)\n",
    "        fitness = (1.0 + (X[0]+X[1]+1.0)*(X[0]+X[1]+1.0)*(19.0-14.0*X[0]+3.0*X[0]*X[0]-14.0*X[1]+6.0*X[0]*X[1]+3.0*X[1]*X[1]))* \\\n",
    "                (30.0 + (2.0*X[0]-3.0*X[1])*(2.0*X[0]-3.0*X[1])*(18.0-32.0*X[0]+12.0*X[0]*X[0]+48.0*X[1]-36.0*X[0]*X[1]+27.0*X[1]*X[1]));\n",
    "\n",
    "        return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ComputeFitness() function takes only one argument - an array X which holds our DNA information, a.k.a our optimization solution parameters. Since the Goldstein-Price function has only two parameters (X and Y), we expect X to have a length of 2. Next, we need a way of identifying the fittest individual inside a population - for this, we write another function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeBestKid(FITNESS):\n",
    "        # Computes the fittest child                              \n",
    "        # FITNESS is an array of dimension (NO_KIDS)\n",
    "        NO_KIDS = len(FITNESS)\n",
    "        BestFitness = 10000.0\n",
    "        BestIndex = -1\n",
    "        for i in range(NO_KIDS):\n",
    "                if (FITNESS[i] < BestFitness):\n",
    "                        BestFitness = FITNESS[i]\n",
    "                        BestIndex = i\n",
    "\n",
    "        return BestIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, as we wish to determine the minimum of the Goldstein-Price function, we are searching for a member of the population with the lowest value of the fitness. We are only interested in returning the best (fittest) member of the population - or specifically, the index to them, which we will require for the next function - the ComputeNextGeneration() function.\n",
    "\n",
    "## Genetic Algorithm Core\n",
    "\n",
    "Below you'll see a section of code which contains the core components of the Differential Evolution (DE) computation. When moving from generation to generation, the DNA of the members evolves through reproduction - that is, parents are selected and the DNA for their offspring selected based on the value of the parents. In this approach, we actually have 3 parents:\n",
    "\n",
    "* Parent A, which is always the member of the generation which is the \"fittest\" - in this case, the parent which has the lowest value of the Goldstein-Price function.\n",
    "* Parents B and C, which are randomly selected parents from the population.\n",
    "\n",
    "When computing the value of a child's DNA, there are two steps - combination and mutation. \n",
    "\n",
    "### Reproduction - Combination\n",
    "\n",
    "In the case of this Differential Evolution algorithm, combination is the linear process by which two parents contribute towards their child's genome. We might imagine that the genome of a child is based on a weighted contribution from their parents:\n",
    "\n",
    "\\begin{align}\n",
    "X_{child} = W_f X_A + (1-W_f) X_B\n",
    "\\end{align}\n",
    "\n",
    "Where $W_f$ is a value between 0 and 1. In the case of the algorithm below, the value of $W_f$ is computed as:\n",
    "\n",
    "\\begin{align}\n",
    "W_f = FR*max(R_f, 1 - R_f)\n",
    "\\end{align}\n",
    "\n",
    "where $R_f$ is a random number generated from a uniform distribution from 0 to 1. In this way, we can see that, while the contribution to the childs genome is random, we always tend to lean towards Parent A - which, as you might recall, was the \"fittest\" parent. Finally, we have a parameter - FR - which is nominally unity (i.e. 1) but can be increased to accelerate convergence on an optimal solution.\n",
    "\n",
    "### Reproduction - Mutation\n",
    "\n",
    "In biology, mutation is the result of an error occuring during the DNA replication process - resulting in an increased variance in population parameters in a seemingly random manner. We have adopted this process in our reproduction phase of our genetic algorithm - the value of a childs genome is subject to random alteration based on the variance of that genome in the population. In the algorithm used in the python script below, we select a third parent (Parent C) to help predict the amount of variance present (for any given genome) which is then used to compute the magnitude of the mutation applied. \n",
    "\n",
    "Taking mutation into account, the value of a new child's genome is:\n",
    "\n",
    "\\begin{align}\n",
    "X_{child} = W_f X_A + (1-W_f) X_B + \\sigma R_n (X_C - X_B)\n",
    "\\end{align}\n",
    "\n",
    "where the first part is the combination process described previously, and $R_n$ is a normally distributed random number with a mean of 0 and a variance of 1 and $\\sigma$ is a solution parameter (nominally 1) which we can control to increase / decrease the amount of mutation present. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMod(X):\n",
    "        if (X > 0.5):\n",
    "                return X\n",
    "        else:\n",
    "                return (1.0-X)\n",
    "            \n",
    "\n",
    "def ComputeNextGeneration(DNA, FITNESS, BESTINDEX, FR, SIGMA):\n",
    "\n",
    "        NO_KIDS,NO_VAR = DNA.shape\n",
    "        trial_dna = np.empty(NO_VAR)\n",
    "\n",
    "        # Assume the next generation will be identical\n",
    "        new_dna = DNA\n",
    "        new_fitness = FITNESS\n",
    "\n",
    "        # Compute a replacement for each member of this generation\n",
    "        for i in range(NO_KIDS):\n",
    "                # Pick parents\n",
    "                Parent_A = BESTINDEX\n",
    "                Parent_B = Parent_A\n",
    "                Parent_C = Parent_A\n",
    "                while ((Parent_A == Parent_B) or (Parent_A == Parent_C) or (Parent_B == Parent_C)):\n",
    "                        # Select Parent B and C randomly from the population\n",
    "                        Parent_B = np.random.randint(NO_KIDS)\n",
    "                        Parent_C = np.random.randint(NO_KIDS)\n",
    "\n",
    "                # Compute the dna of the trial child\n",
    "                for j in range(NO_VAR):\n",
    "                        Rf = FR*MaxMod(np.random.rand())\n",
    "                        Rnf = SIGMA*np.random.randn()\n",
    "                        trial_dna[j] = Rf*DNA[Parent_A,j]+(1.0-Rf)*DNA[Parent_B,j] + Rnf*(DNA[Parent_B,j]-DNA[Parent_C,j])\n",
    "\n",
    "                # Compute the fitness of the trial child\n",
    "                trial_fitness = ComputeFitness(trial_dna)\n",
    "\n",
    "                \n",
    "                if (np.abs(trial_fitness) < np.abs(FITNESS[i])):\n",
    "                        # This trial child has better dna. Make the change.\n",
    "                        new_fitness[i] = trial_fitness\n",
    "                        new_dna[i,:] = trial_dna\n",
    "\n",
    "        # Return the next generations data\n",
    "        return new_dna, new_fitness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Simulation\n",
    "\n",
    "Now we have all the functions we need taken care of, we can start by choosing the number of kids in each generation (NO_KIDS), the number of solution parameters we have (NO_VAR = 2 for the Goldstein-Price function), the number of generations (NO_GEN) and the values of $FR$ and $\\sigma$ (SIGMA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commence the main program sequence\n",
    "# Assign solution parameters\n",
    "NO_KIDS = 30\n",
    "NO_VAR = 2\n",
    "NO_GEN = 10\n",
    "FR = 1.0\n",
    "SIGMA = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set the initial values of the dna for the NO_KIDS kids in the population. Ideally, we would like the range of these initial values to be large enough to capture the global minima / maxima, but as we are about to see, this is not required: let's randomly guess the solutions for our minimization problem as being uniformly distributed across the range 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the problem\n",
    "kid_dna = np.random.rand(NO_KIDS, NO_VAR)\n",
    "kid_fitness = np.zeros(NO_KIDS)\n",
    "history_fitness = np.empty(NO_GEN)\n",
    "history_dna = np.zeros((NO_GEN,NO_VAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, above, we assign an array of zeros for the kids fitness. Let's compute the fitness for each child, and then find the best child - in this case, the one with the lowest value of the Goldstein-Price function - by calling some of the functions decribed previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best kid in the population has fitness 674.849 at (0.0635186, 0.0436979)\n"
     ]
    }
   ],
   "source": [
    "# Find the child with the best dna\n",
    "for i in range(NO_KIDS):\n",
    "        kid_fitness[i] = ComputeFitness(kid_dna[i,:])\n",
    "# Find the Index of the best kid based on fitness\n",
    "BestKid = ComputeBestKid(kid_fitness)\n",
    "print(\"The best kid in the population has fitness %g at (%g, %g)\" % (kid_fitness[BestKid], kid_dna[BestKid,0], kid_dna[BestKid,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to start our evolution simulation, where we have subsequent generations of children working together to produce new children whose genetic properties are computed using the algorithm we described above. For each generation, we need to:\n",
    "\n",
    "* Compute the new generation's genetic properties (ComputeNextGeneration()), and\n",
    "* Find the \"alpha\" in that generation (i.e. the best one) (ComputeBestKid())\n",
    "\n",
    "We are also going to save some historical data so we can better understand the evolution towards our optimal result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - best fitness = 3 at (9.25907e-06, -1.00002)\n",
      "Iteration 1 - best fitness = 3 at (2.15225e-05, -0.999999)\n",
      "Iteration 2 - best fitness = 3 at (3.42681e-06, -0.999993)\n",
      "Iteration 3 - best fitness = 3 at (3.42681e-06, -0.999993)\n",
      "Iteration 4 - best fitness = 3 at (-1.42156e-06, -1)\n",
      "Iteration 5 - best fitness = 3 at (-2.29213e-07, -1)\n",
      "Iteration 6 - best fitness = 3 at (-2.29213e-07, -1)\n",
      "Iteration 7 - best fitness = 3 at (-3.54483e-07, -1)\n",
      "Iteration 8 - best fitness = 3 at (-2.61496e-07, -1)\n",
      "Iteration 9 - best fitness = 3 at (2.30424e-07, -1)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over generations to evolve the population\n",
    "for gen in range(NO_GEN):\n",
    "        kid_dna, kid_fitness = ComputeNextGeneration(kid_dna,kid_fitness,BestKid, FR, SIGMA)\n",
    "        BestKid = ComputeBestKid(kid_fitness)\n",
    "        history_fitness[gen] = kid_fitness[BestKid]\n",
    "        history_dna[gen,:] = kid_dna[BestKid,:]\n",
    "        # Write a report\n",
    "        print(\"Iteration %d - best fitness = %g at (%g, %g)\" % (gen, kid_fitness[BestKid], kid_dna[BestKid,0], kid_dna[BestKid,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "If everything has gone to plan, we can see that our population has produced a child containing our optimal solution, or something close to it. Keep in mind the analytical minima for the Goldstein-Price function is 3, located at (0,-1) - if we are lucky, we shoudl see that we have converged on this result. The iteration towards this result is not guaranteed to be smooth - advances through evolution rarely are. However, you might experiment with the values of $FR$ and $\\sigma$ to see how they influence the rate at which we reach our solution.\n",
    "\n",
    "Finally, let's have a look at the convergence on a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(history_dna)\n",
    "ax.set(xlabel='Generation Number',ylabel='DNA Values')\n",
    "ax2 = ax.twinx()\n",
    "ax2.semilogy(history_fitness,'r')\n",
    "ax2.set(ylabel='Fitness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's look at the value of the average fitness computed across for the entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== FINAL REPORT ========\n",
      "Average fitness of final generation = 3.30492\n",
      "Best Kid's Fitness: 3.00742\n",
      "Best Kid's DNA Parameter values:\n",
      "-- DNA Parameter 0 = -0.00298044\n",
      "-- DNA Parameter 1 = -1.00428\n"
     ]
    }
   ],
   "source": [
    "print(\"====== FINAL REPORT ========\")\n",
    "print(\"Average fitness of final generation = %g\" % np.mean(kid_fitness))\n",
    "print(\"Best Kid's Fitness: %g\" % kid_fitness[BestKid])\n",
    "print(\"Best Kid's DNA Parameter values:\")\n",
    "for i in range(NO_VAR):\n",
    "        print(\"-- DNA Parameter %d = %g\" % (i,kid_dna[BestKid,i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "Genetic Algorithms (GA's) have the ability to find global maxima or minima in functions which contain many local minima / maxima, and for this reason have found quite extensive use in complication optimization problems. Feel free to experiment with the function you are optimizing - you can find a list of functions used to test optimization routines by googling \"optimization test cases\".  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
